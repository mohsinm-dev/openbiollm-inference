"""
OpenBioLLM Inference package.

Provides:
- Local Apple Silicon runners (GGUF via llama.cpp; MLX via mlx-lm)
- GPU serving via vLLM + FastAPI proxy
"""
