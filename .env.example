# FastAPI proxy settings
APP_HOST=0.0.0.0
APP_PORT=8000
LOG_LEVEL=INFO

# vLLM container settings
VLLM_MODEL_ID=aaditya/Llama3-OpenBioLLM-8B
VLLM_MAX_MODEL_LEN=8192
VLLM_TP_SIZE=1
VLLM_PORT=8001

# Proxy talks to vLLM's OpenAI-compatible endpoint
VLLM_BASE_URL=http://vllm:8001
VLLM_API_KEY=not-required
